# -*- coding: utf-8 -*-
"""ML Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r_qfoWCsKSl7oh_m5kJ-ZRtw4tDEcnjO

Classification Model(decision tree)
"""

# Commented out IPython magic to ensure Python compatibility.
# -*- coding: utf-8 -*-
# PIMA Indians Diabetes – Improved ANN Classification

# 1. Setup & Libraries
import pandas as pd
import numpy as np

import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    accuracy_score,
    classification_report,
    confusion_matrix,
    ConfusionMatrixDisplay
)

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.callbacks import EarlyStopping

# %matplotlib inline

# Reproducibility
np.random.seed(42)
tf.random.set_seed(42)

# 2. Load dataset
url = "https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv"
columns = [
    "Pregnancies",
    "Glucose",
    "BloodPressure",
    "SkinThickness",
    "Insulin",
    "BMI",
    "DiabetesPedigreeFunction",
    "Age",
    "Outcome"
]

df = pd.read_csv(url, names=columns)

print("=== RAW DATASET ===")
print("Shape:", df.shape)
print(df.head())
print("\nInfo:")
print(df.info())
print("\nStatistical summary:")
print(df.describe())

print("\nMissing values count (raw):")
print(df.isnull().sum())
print("Duplicate rows count (raw):", df.duplicated().sum())

# 3. Handle impossible zeros as missing (same approach as other models)
cols_with_missing = ["Glucose", "BloodPressure", "SkinThickness", "Insulin", "BMI"]
df[cols_with_missing] = df[cols_with_missing].replace(0, np.nan)

print("\nMissing values after converting 0 -> NaN:")
print(df.isnull().sum())

# Median imputation
for col in cols_with_missing:
    df[col] = df[col].fillna(df[col].median())

print("\nMissing values after median imputation:")
print(df.isnull().sum())

# 4. Remove duplicates ONLY (no outlier removal)
print(f"\nShape before removing duplicates: {df.shape}")
df = df.drop_duplicates()
print(f"Shape after removing duplicates: {df.shape}")

# Simple BMI category (not used by ANN, just for completeness/analysis)
df["BMI_Category"] = pd.cut(
    df["BMI"],
    bins=[0, 18.5, 25, 30, 100],
    labels=["Underweight", "Normal", "Overweight", "Obese"]
)

print("\n=== CLEANED DATASET SUMMARY ===")
print("Final shape:", df.shape)
print("Number of diabetic patients:", int(df["Outcome"].sum()))
print("Diabetes prevalence: {:.2f}%".format(
    df["Outcome"].sum() / len(df) * 100
))
print("\nData types:")
print(df.dtypes)

# 5. Prepare data for ANN
feature_cols = [
    "Pregnancies",
    "Glucose",
    "BloodPressure",
    "SkinThickness",
    "Insulin",
    "BMI",
    "DiabetesPedigreeFunction",
    "Age"
]

X = df[feature_cols].values
y = df["Outcome"].values  # 0 or 1

print("\nFeature matrix shape:", X.shape)
print("Target vector shape:", y.shape)

# Train-test split (stratified)
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    stratify=y,
    random_state=42
)

print("\n=== TRAIN/TEST SPLIT ===")
print("Training samples:", X_train.shape[0])
print("Test samples:", X_test.shape[0])

# 6. Feature scaling (VERY IMPORTANT for ANN)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 7. Build ANN model
model = Sequential([
    Dense(16, activation="relu", input_shape=(X_train_scaled.shape[1],)),
    Dense(8, activation="relu"),
    Dense(1, activation="sigmoid")  # output: probability of diabetes
])

model.compile(
    optimizer="adam",
    loss="binary_crossentropy",
    metrics=["accuracy"]
)

print("\n=== MODEL SUMMARY ===")
model.summary()

# 8. Callbacks – EarlyStopping
early_stop = EarlyStopping(
    monitor="val_loss",
    patience=10,
    restore_best_weights=True
)

# OPTIONAL: class weights to give more importance to diabetics
USE_CLASS_WEIGHT = False  # set to True if you want to try balancing

if USE_CLASS_WEIGHT:
    # compute simple class weights inversely proportional to frequency
    from sklearn.utils.class_weight import compute_class_weight
    classes = np.unique(y_train)
    class_weights_values = compute_class_weight(
        class_weight="balanced",
        classes=classes,
        y=y_train
    )
    class_weight = {cls: w for cls, w in zip(classes, class_weights_values)}
    print("\nClass weights:", class_weight)
else:
    class_weight = None

# 9. Train the model
history = model.fit(
    X_train_scaled,
    y_train,
    validation_split=0.2,
    epochs=100,
    batch_size=32,
    callbacks=[early_stop],
    class_weight=class_weight,
    verbose=1
)

# 10. Plot training history (loss and accuracy)
history_dict = history.history

plt.figure(figsize=(6, 4))
plt.plot(history_dict["loss"], label="Train loss")
plt.plot(history_dict["val_loss"], label="Val loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("ANN Training vs Validation Loss")
plt.legend()
plt.tight_layout()
plt.show()

plt.figure(figsize=(6, 4))
plt.plot(history_dict["accuracy"], label="Train acc")
plt.plot(history_dict["val_accuracy"], label="Val acc")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.title("ANN Training vs Validation Accuracy")
plt.legend()
plt.tight_layout()
plt.show()

# 11. Evaluate on test set
test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)
print("\n=== ANN PERFORMANCE ON TEST SET ===")
print(f"Test Loss     : {test_loss:.4f}")
print(f"Test Accuracy : {test_accuracy:.4f}")

# Predict probabilities and then classes with threshold 0.5
y_prob = model.predict(X_test_scaled)
y_pred = (y_prob >= 0.5).astype(int).ravel()

acc = accuracy_score(y_test, y_pred)
print(f"\nAccuracy (threshold=0.5): {acc:.4f}")

print("\nClassification Report:")
print(classification_report(y_test, y_pred, digits=4))

cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)

plt.figure(figsize=(5, 4))
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])
disp.plot(values_format="d")
plt.title("ANN Confusion Matrix (threshold = 0.5)")
plt.tight_layout()
plt.show()

# 12. (Optional) Try a different threshold (e.g. 0.4) to boost recall for diabetics
THRESHOLD = 0.4
y_pred_04 = (y_prob >= THRESHOLD).astype(int).ravel()
acc_04 = accuracy_score(y_test, y_pred_04)

print(f"\n=== PERFORMANCE WITH THRESHOLD = {THRESHOLD} ===")
print(f"Accuracy: {acc_04:.4f}")
print("Classification Report:")
print(classification_report(y_test, y_pred_04, digits=4))

cm_04 = confusion_matrix(y_test, y_pred_04)
print("Confusion Matrix:")
print(cm_04)

plt.figure(figsize=(5, 4))
disp_04 = ConfusionMatrixDisplay(confusion_matrix=cm_04, display_labels=[0, 1])
disp_04.plot(values_format="d")
plt.title(f"ANN Confusion Matrix (threshold = {THRESHOLD})")
plt.tight_layout()
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# -*- coding: utf-8 -*-
# PIMA Indians Diabetes – Decision Tree Classification (Optimised for Accuracy)

# 1. Setup & Libraries
import pandas as pd
import numpy as np

import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import (
    accuracy_score,
    classification_report,
    confusion_matrix,
    ConfusionMatrixDisplay
)

# %matplotlib inline

# For reproducibility
np.random.seed(42)

# 2. Load dataset
url = "https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv"
columns = [
    "Pregnancies",
    "Glucose",
    "BloodPressure",
    "SkinThickness",
    "Insulin",
    "BMI",
    "DiabetesPedigreeFunction",
    "Age",
    "Outcome"
]

df = pd.read_csv(url, names=columns)

print("=== RAW DATASET ===")
print("Shape:", df.shape)
print(df.head())
print("\nInfo:")
print(df.info())
print("\nStatistical summary:")
print(df.describe())

print("\nMissing values count (raw):")
print(df.isnull().sum())
print("Duplicate rows count (raw):", df.duplicated().sum())

# 3. Handle impossible zeros as missing
cols_with_missing = ["Glucose", "BloodPressure", "SkinThickness", "Insulin", "BMI"]
df[cols_with_missing] = df[cols_with_missing].replace(0, np.nan)

print("\nMissing values after converting 0 -> NaN:")
print(df.isnull().sum())

# Median imputation (avoid chained assignment)
for col in cols_with_missing:
    df[col] = df[col].fillna(df[col].median())

print("\nMissing values after median imputation:")
print(df.isnull().sum())

# 4. Remove duplicates
print(f"\nShape before removing duplicates: {df.shape}")
df = df.drop_duplicates()
print(f"Shape after removing duplicates: {df.shape}")

# 5. Optional: outlier removal using 3*IQR
# Set this to True if you WANT to remove extreme outliers
REMOVE_OUTLIERS = False  # <<< main switch

if REMOVE_OUTLIERS:
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    Q1 = df[numeric_cols].quantile(0.25)
    Q3 = df[numeric_cols].quantile(0.75)
    IQR = Q3 - Q1

    outlier_mask = ((df[numeric_cols] < (Q1 - 3 * IQR)) |
                    (df[numeric_cols] > (Q3 + 3 * IQR))).any(axis=1)

    print(f"\nRows flagged as outliers (3*IQR): {outlier_mask.sum()}")
    df_clean = df.loc[~outlier_mask].copy()
else:
    df_clean = df.copy()

print("Shape after outlier handling:", df_clean.shape)

# 6. Type cleaning & simple feature engineering
df_clean["Pregnancies"] = df_clean["Pregnancies"].astype(int)
df_clean["Age"] = df_clean["Age"].astype(int)

df_clean["BMI_Category"] = pd.cut(
    df_clean["BMI"],
    bins=[0, 18.5, 25, 30, 100],
    labels=["Underweight", "Normal", "Overweight", "Obese"]
)

print("\n=== CLEANED DATASET SUMMARY ===")
print("Final shape:", df_clean.shape)
print("Number of diabetic patients:", int(df_clean["Outcome"].sum()))
print("Diabetes prevalence: {:.2f}%".format(
    df_clean["Outcome"].sum() / len(df_clean) * 100
))
print("\nData types:")
print(df_clean.dtypes)

# 7. Quick target distribution (cleaned)
plt.figure(figsize=(5, 4))
sns.countplot(x="Outcome", data=df_clean)
plt.title("Distribution of Diabetes Outcomes (Cleaned Dataset)")
plt.show()

# 8. Prepare data for Decision Tree
feature_cols = [
    "Pregnancies",
    "Glucose",
    "BloodPressure",
    "SkinThickness",
    "Insulin",
    "BMI",
    "DiabetesPedigreeFunction",
    "Age"
]

X = df_clean[feature_cols]
y = df_clean["Outcome"]

# Train-test split (stratified to keep class balance)
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    stratify=y,
    random_state=42
)

print("\n=== TRAIN/TEST SPLIT ===")
print("Training samples:", X_train.shape[0])
print("Test samples:", X_test.shape[0])

# 9. Baseline Decision Tree (optimised for accuracy, no class_weight)
baseline_dt = DecisionTreeClassifier(
    criterion="gini",
    max_depth=None,        # let the tree grow; regularised by other params & data
    random_state=42
)

baseline_dt.fit(X_train, y_train)

# Evaluate baseline
y_pred_base = baseline_dt.predict(X_test)
print("\n=== BASELINE DECISION TREE ===")
print(f"Accuracy: {accuracy_score(y_test, y_pred_base):.4f}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred_base, digits=4))

cm_base = confusion_matrix(y_test, y_pred_base)
print("Confusion Matrix:")
print(cm_base)

plt.figure(figsize=(5, 4))
disp_base = ConfusionMatrixDisplay(confusion_matrix=cm_base, display_labels=[0, 1])
disp_base.plot(values_format="d")
plt.title("Baseline Decision Tree – Confusion Matrix")
plt.tight_layout()
plt.show()

# 5-fold CV accuracy for baseline
cv_acc_base = cross_val_score(baseline_dt, X, y, cv=5, scoring="accuracy")
print("\n=== BASELINE 5-FOLD CV (ACCURACY) ===")
print("Accuracy scores:", cv_acc_base)
print("Mean accuracy: {:.4f} ± {:.4f}".format(cv_acc_base.mean(), cv_acc_base.std()))

# 10. Hyperparameter tuning (focus on accuracy)
param_grid = {
    "max_depth": [3, 4, 5, 6, None],
    "min_samples_split": [2, 5, 10, 20],
    "min_samples_leaf": [1, 2, 5, 10],
    "criterion": ["gini", "entropy"]
}

dt_for_grid = DecisionTreeClassifier(
    random_state=42
)

grid = GridSearchCV(
    dt_for_grid,
    param_grid,
    scoring="accuracy",  # <<< optimise for accuracy now
    cv=5,
    n_jobs=-1
)

grid.fit(X_train, y_train)

print("\n=== GRID SEARCH RESULTS (ACCURACY) ===")
print("Best parameters:", grid.best_params_)
print("Best CV accuracy: {:.4f}".format(grid.best_score_))

best_dt = grid.best_estimator_

# 11. Evaluate tuned model on test set
y_pred_best = best_dt.predict(X_test)

print("\n=== TUNED DECISION TREE (BEST ESTIMATOR) ===")
print(f"Accuracy: {accuracy_score(y_test, y_pred_best):.4f}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred_best, digits=4))

cm_best = confusion_matrix(y_test, y_pred_best)
print("Confusion Matrix:")
print(cm_best)

plt.figure(figsize=(5, 4))
disp_best = ConfusionMatrixDisplay(confusion_matrix=cm_best, display_labels=[0, 1])
disp_best.plot(values_format="d")
plt.title("Tuned Decision Tree – Confusion Matrix")
plt.tight_layout()
plt.show()

# 5-fold CV accuracy for tuned model (on full X, y)
cv_acc_best = cross_val_score(best_dt, X, y, cv=5, scoring="accuracy")
print("\n=== TUNED MODEL 5-FOLD CV (ACCURACY) ===")
print("Accuracy scores:", cv_acc_best)
print("Mean accuracy: {:.4f} ± {:.4f}".format(cv_acc_best.mean(), cv_acc_best.std()))

# 12. Feature importances (from tuned tree)
importances = pd.Series(best_dt.feature_importances_, index=feature_cols).sort_values(ascending=False)
print("\n=== FEATURE IMPORTANCES (TUNED TREE) ===")
print(importances)

plt.figure(figsize=(8, 5))
importances.plot(kind="bar")
plt.title("Tuned Decision Tree – Feature Importances")
plt.ylabel("Importance")
plt.tight_layout()
plt.show()

# 13. (Optional) Visualise tuned tree
plt.figure(figsize=(18, 10))
plot_tree(
    best_dt,
    feature_names=feature_cols,
    class_names=["No Diabetes", "Diabetes"],
    filled=True,
    rounded=True,
    fontsize=8
)
plt.title("Tuned Decision Tree for Diabetes Classification (PIMA Dataset) – Accuracy-Optimised")
plt.show()

"""Regression Model(Linear Regression)


"""

# Commented out IPython magic to ensure Python compatibility.
# -*- coding: utf-8 -*-
# PIMA Indians Diabetes – Improved Regression Models (Predicting Glucose)
# - Baseline Linear Regression
# - Polynomial (degree 2) Linear Regression

# 1. Setup & Libraries
import pandas as pd
import numpy as np

import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import Pipeline
from sklearn.metrics import (
    mean_absolute_error,
    mean_squared_error,
    r2_score
)

# %matplotlib inline

# For reproducibility
np.random.seed(42)

# 2. Load dataset
url = "https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv"
columns = [
    "Pregnancies",
    "Glucose",
    "BloodPressure",
    "SkinThickness",
    "Insulin",
    "BMI",
    "DiabetesPedigreeFunction",
    "Age",
    "Outcome"
]

df = pd.read_csv(url, names=columns)

print("=== RAW DATASET ===")
print("Shape:", df.shape)
print(df.head())
print("\nInfo:")
print(df.info())
print("\nStatistical summary:")
print(df.describe())

print("\nMissing values count (raw):")
print(df.isnull().sum())
print("Duplicate rows count (raw):", df.duplicated().sum())

# 3. Handle impossible zeros as missing
cols_with_missing = ["Glucose", "BloodPressure", "SkinThickness", "Insulin", "BMI"]
df[cols_with_missing] = df[cols_with_missing].replace(0, np.nan)

print("\nMissing values after converting 0 -> NaN:")
print(df.isnull().sum())

# Median imputation (no chained assignment)
for col in cols_with_missing:
    df[col] = df[col].fillna(df[col].median())

print("\nMissing values after median imputation:")
print(df.isnull().sum())

# 4. Remove duplicates (no outlier removal)
print(f"\nShape before removing duplicates: {df.shape}")
df = df.drop_duplicates()
print(f"Shape after removing duplicates: {df.shape}")

# 5. Simple feature engineering (for analysis only, not used as numeric feature)
df["BMI_Category"] = pd.cut(
    df["BMI"],
    bins=[0, 18.5, 25, 30, 100],
    labels=["Underweight", "Normal", "Overweight", "Obese"]
)

print("\n=== CLEANED DATASET SUMMARY ===")
print("Final shape:", df.shape)
print("Data types:")
print(df.dtypes)

# 6. Quick EDA for regression target (Glucose)
plt.figure(figsize=(6, 4))
sns.histplot(df["Glucose"], kde=True)
plt.title("Distribution of Glucose (Target for Regression)")
plt.xlabel("Glucose")
plt.ylabel("Frequency")
plt.tight_layout()
plt.show()

# 7. Prepare data for Regression
# Target: Glucose
# Features: all numeric predictors except Glucose and Outcome
feature_cols = [
    "Pregnancies",
    "BloodPressure",
    "SkinThickness",
    "Insulin",
    "BMI",
    "DiabetesPedigreeFunction",
    "Age"
]

X = df[feature_cols]
y = df["Glucose"]

print("\nFeature matrix shape:", X.shape)
print("Target vector shape:", y.shape)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42
)

print("\n=== TRAIN/TEST SPLIT ===")
print("Training samples:", X_train.shape[0])
print("Test samples:", X_test.shape[0])

# Helper function to print metrics
def print_regression_metrics(name, y_true, y_pred):
    mae = mean_absolute_error(y_true, y_pred)
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_true, y_pred)
    print(f"\n=== {name} – Test Performance ===")
    print(f"MAE : {mae:.4f}")
    print(f"MSE : {mse:.4f}")
    print(f"RMSE: {rmse:.4f}")
    print(f"R²  : {r2:.4f}")
    return mae, mse, rmse, r2

# 8. Baseline Linear Regression
lin_reg = LinearRegression()
lin_reg.fit(X_train, y_train)

print("\n=== BASELINE LINEAR REGRESSION ===")
print("Intercept:", lin_reg.intercept_)
print("Coefficients:")
for name, coef in zip(feature_cols, lin_reg.coef_):
    print(f"  {name}: {coef:.4f}")

y_pred_lin = lin_reg.predict(X_test)
mae_lin, mse_lin, rmse_lin, r2_lin = print_regression_metrics(
    "Baseline Linear Regression", y_test, y_pred_lin
)

# Cross-validation R²
cv_scores_lin = cross_val_score(lin_reg, X, y, cv=5, scoring="r2")
print("\n=== BASELINE LINEAR REGRESSION – 5-FOLD CV R² ===")
print("CV scores:", cv_scores_lin)
print("Mean R²: {:.4f} ± {:.4f}".format(cv_scores_lin.mean(), cv_scores_lin.std()))

# 9. Improved model: Polynomial Regression (degree 2) + Linear Regression
poly_model = Pipeline([
    ("poly", PolynomialFeatures(degree=2, include_bias=False)),
    ("linreg", LinearRegression())
])

poly_model.fit(X_train, y_train)
y_pred_poly = poly_model.predict(X_test)
mae_poly, mse_poly, rmse_poly, r2_poly = print_regression_metrics(
    "Polynomial (degree 2) Linear Regression", y_test, y_pred_poly
)

# Cross-validation for polynomial model
cv_scores_poly = cross_val_score(poly_model, X, y, cv=5, scoring="r2")
print("\n=== POLYNOMIAL (DEGREE 2) REGRESSION – 5-FOLD CV R² ===")
print("CV scores:", cv_scores_poly)
print("Mean R²: {:.4f} ± {:.4f}".format(cv_scores_poly.mean(), cv_scores_poly.std()))

# 10. Compare baseline vs polynomial visually (Actual vs Predicted)
plt.figure(figsize=(6, 6))
plt.scatter(y_test, y_pred_lin, alpha=0.7, label="Linear")
plt.scatter(y_test, y_pred_poly, alpha=0.7, marker="x", label="Poly (deg 2)")
line_min = min(y_test.min(), y_pred_lin.min(), y_pred_poly.min())
line_max = max(y_test.max(), y_pred_lin.max(), y_pred_poly.max())
plt.plot([line_min, line_max], [line_min, line_max], linestyle="--")
plt.xlabel("Actual Glucose")
plt.ylabel("Predicted Glucose")
plt.title("Actual vs Predicted Glucose – Linear vs Polynomial Regression")
plt.legend()
plt.tight_layout()
plt.show()

# 11. Residual plot for best model (choose poly if R² is higher, else linear)
if r2_poly >= r2_lin:
    best_name = "Polynomial (degree 2) Regression"
    best_pred = y_pred_poly
else:
    best_name = "Baseline Linear Regression"
    best_pred = y_pred_lin

residuals = y_test - best_pred

plt.figure(figsize=(6, 4))
plt.scatter(best_pred, residuals, alpha=0.7)
plt.axhline(0, linestyle="--")
plt.xlabel("Predicted Glucose")
plt.ylabel("Residuals (Actual - Predicted)")
plt.title(f"Residual Plot – {best_name}")
plt.tight_layout()
plt.show()

print(f"\nBest model on test R²: {best_name}")
print(f"R² (Linear):   {r2_lin:.4f}")
print(f"R² (Poly d=2): {r2_poly:.4f}")

"""Neural Network Model

Random forest
"""

